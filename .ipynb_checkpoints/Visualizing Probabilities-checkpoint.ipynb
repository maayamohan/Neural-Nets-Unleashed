{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18092f2a-cdd7-4dfe-88ca-305a0ab92bd7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2437011-0cdd-406f-825f-f187e728f3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_next_token_predictions(text, model_name=\"distilgpt2\", top_k=10):\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "    print(model.transformer.wte)\n",
    "    \n",
    "    \n",
    "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "    \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "    \n",
    "    \n",
    "    next_token_logits = logits[0, -1, :]\n",
    "    probabilities = torch.nn.functional.softmax(next_token_logits, dim=0)\n",
    "    \n",
    "    \n",
    "    top_k_probs, top_k_indices = torch.topk(probabilities, top_k)\n",
    "    \n",
    "    \n",
    "    top_k_tokens = [tokenizer.decode([idx.item()]) for idx in top_k_indices]\n",
    "    \n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    \n",
    "    bars = plt.barh(range(top_k), top_k_probs.numpy())\n",
    "    \n",
    "    \n",
    "    plt.yticks(range(top_k), top_k_tokens)\n",
    "    plt.xlabel('Probability')\n",
    "    plt.title(f'Top {top_k} Next Token Predictions\\nInput: \"{text}\"')\n",
    "    \n",
    "    \n",
    "    for i, bar in enumerate(bars):\n",
    "        width = bar.get_width()\n",
    "        plt.text(width, bar.get_y() + bar.get_height()/2,\n",
    "                f'{width:.3f}',\n",
    "                ha='left', va='center', fontweight='bold')\n",
    "    \n",
    "    \n",
    "    sm = plt.cm.ScalarMappable(cmap=plt.cm.Blues, \n",
    "                              norm=plt.Normalize(vmin=min(top_k_probs), \n",
    "                                               vmax=max(top_k_probs)))\n",
    "    for bar, prob in zip(bars, top_k_probs):\n",
    "        bar.set_color(sm.to_rgba(prob))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0dda177-2fdd-4801-99d2-760fbd093985",
   "metadata": {},
   "outputs": [],
   "source": [
    "def demonstrate_predictions():\n",
    "    examples = [\n",
    "        \"The cat sat on the\",\n",
    "        \"I love to eat\",\n",
    "        \"The weather today is\",\n",
    "        \"Once upon a\"\n",
    "    ]\n",
    "    \n",
    "    for example in examples:\n",
    "        print(f\"\\nAnalyzing: '{example}'\")\n",
    "        visualize_next_token_predictions(example)\n",
    "        input(\"Press Enter to continue to next example...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38c811e-4185-44ef-aa0c-1aa12ab45adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "demonstrate_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15debda4-906f-4559-954d-10fb3dcdae79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
