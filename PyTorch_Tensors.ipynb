{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dXK1NihkqaSw"
   },
   "source": [
    "# Introduction to PyTorch Tensors\n",
    "\n",
    "- Tensors are the basic units of every PyTorch program.\n",
    "- Tensors are really similar to the concept of Numpy arrays, the only and most significant difference being: They can be run on the *GPU*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6aC7aeX_tg9F"
   },
   "source": [
    "## First we import PyTorch!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "VSCffJSytfsH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your PyTorch is on version:2.2.2.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"Your PyTorch is on version:{torch.__version__}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iT94EhWttCnV"
   },
   "source": [
    "## Dear god, give me a tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "JAAWLsA9qQt1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n",
      "torch.float32\n",
      "cpu\n",
      "False\n",
      "None\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "myNewTens = torch.empty(2,3)\n",
    "print(myNewTens.shape)\n",
    "print(myNewTens.dtype)\n",
    "print(myNewTens.device)\n",
    "print(myNewTens.requires_grad)\n",
    "print(myNewTens.grad)\n",
    "print(myNewTens) # will contain random garbage since we've not initialized it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aH2k5QvQuPXB"
   },
   "source": [
    "### Yay! We just created our *first* tensor!\n",
    "\n",
    "Now lets take a breather and think of what we just did.\n",
    "- You just created a $2 \\times 3$ tensor.\n",
    "- `shape` tells us the dimensions of the tensor.\n",
    "- `dtype` tells us the *type* of data stored within this tensor.\n",
    "- `device` tells us the device on which the tensor is allocated.\n",
    "- `requires_grad` determines whether gradients must be computed for the tensor.\n",
    "- `grad` is None on startup but becomes a tensor of gradients after a backward pass."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cuWGvE43hQ6R"
   },
   "source": [
    "## Playing around with Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "62nuBohjhyAG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.])\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n"
     ]
    }
   ],
   "source": [
    "# Create Tensors from Python lists\n",
    "l = [1, 2, 3]\n",
    "tensor = torch.Tensor(l)\n",
    "print(tensor)\n",
    "# You could even stack multiple lists together and make a multidimensional tensor\n",
    "l1 = [1, 2, 3]\n",
    "l2 = [4, 5, 6]\n",
    "tensor = torch.Tensor([l1, l2])\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "th0GBfOYh90K"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1264, 0.7393, 0.2339],\n",
      "        [0.4104, 0.2174, 0.8689]])\n"
     ]
    }
   ],
   "source": [
    "# You can create a Tensor filled with random numbers\n",
    "tensor = torch.rand(2, 3)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "keDVW8lqie55"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# Create a matrix of all zeros\n",
    "tensor = torch.zeros(2, 3)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "U3ubnkNqioCu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# Create a matrix of all zeros and explicitly set data type to be double\n",
    "tensor = torch.zeros(2, 3, dtype=torch.double)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LrPDCVwejKF-"
   },
   "source": [
    "### Common Tensor operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "9_3v1wteisQx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n",
      "torch.Size([2, 3, 4])\n",
      "torch.Size([2, 3, 4, 5])\n"
     ]
    }
   ],
   "source": [
    "# Finding size of a 1-D tensor\n",
    "tensor = torch.zeros(2, 3)\n",
    "print(tensor.size())\n",
    "\n",
    "# Finding the size of a 2-D tensor\n",
    "tensor = torch.zeros(2, 3, 4)\n",
    "print(tensor.size())\n",
    "\n",
    "# Finding the size of a 3-D tensor\n",
    "tensor = torch.zeros(2, 3, 4, 5)\n",
    "print(tensor.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "1HTu3MJHiy8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:\n",
      "tensor([[0.6493, 0.2840, 0.1096],\n",
      "        [0.7859, 0.2019, 0.8326]])\n",
      "\n",
      "y:\n",
      "tensor([[0.8261, 0.1645, 0.8392],\n",
      "        [0.5429, 0.2083, 0.4666]])\n",
      "\n",
      "z = x + y:\n",
      "tensor([[1.4753, 0.4484, 0.9488],\n",
      "        [1.3288, 0.4102, 1.2992]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Arithmetic operations on 2 tensors\n",
    "x = torch.rand(2, 3)\n",
    "y = torch.rand(2, 3)\n",
    "z = x + y\n",
    "\n",
    "print(f\"x:\\n{x}\\n\")\n",
    "print(f\"y:\\n{y}\\n\")\n",
    "print(f\"z = x + y:\\n{z}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "tkYL4c1lkPhB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.4753, 0.4484, 0.9488],\n",
      "        [1.3288, 0.4102, 1.2992]])\n"
     ]
    }
   ],
   "source": [
    "# Special \"inplace\" functions\n",
    "\n",
    "y.add_(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AcbNhvuokiqF"
   },
   "source": [
    "Methods (usually methods ending with an underscore like `add_()`) are called **In-place** operations.\n",
    "This means that they don't make a *copy* of the result in memory. They literally perform the operation on the `y` matrix. This is crucial for memory sensitive aplications.\n",
    "\n",
    "Here's a *great* blog on the [Dangers of Inplace Methods](https://lernapparat.de/pytorch-inplace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "oR6G2DQekh2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1862, 0.1528, 0.3280],\n",
      "        [0.3070, 0.2629, 0.4457]])\n",
      "tensor(0.2629)\n"
     ]
    }
   ],
   "source": [
    "# Indexing into a Tensor\n",
    "x = torch.rand(2, 3)\n",
    "print(x)\n",
    "print(x[1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "jhFO7PmNJIwI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4165, 0.0620, 0.7896],\n",
      "        [0.4939, 0.2519, 0.0606]])\n",
      "tensor([0.9365, 0.9450, 0.8920])\n",
      "tensor([[1.3530, 1.0070, 1.6816],\n",
      "        [1.4304, 1.1970, 0.9526]])\n"
     ]
    }
   ],
   "source": [
    "# Broadcasting tensors\n",
    "x = torch.rand(2, 3)\n",
    "y = torch.rand(3)\n",
    "print(x)\n",
    "print(y)\n",
    "z = x + y\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "MON4jdLoond_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5438, 0.9323, 0.6202],\n",
      "        [0.1947, 0.2302, 0.5878]])\n",
      "tensor([[0.5438, 0.9323],\n",
      "        [0.6202, 0.1947],\n",
      "        [0.2302, 0.5878]])\n",
      "tensor([0.5438, 0.9323, 0.6202, 0.1947, 0.2302, 0.5878])\n",
      "tensor([[0.5438, 0.9323],\n",
      "        [0.6202, 0.1947],\n",
      "        [0.2302, 0.5878]])\n"
     ]
    }
   ],
   "source": [
    "# Reshaping tensors\n",
    "x = torch.rand(2, 3)\n",
    "print(x)\n",
    "y = x.view(3, 2)\n",
    "print(y)\n",
    "z = x.view(6)\n",
    "print(z)\n",
    "w = x.view(-1, 2) # -1 is inferred from other dimeensions\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "nAOIKJuPpKCE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Tensor: tensor([1., 1., 1., 1., 1.])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Numpy is not available",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPyTorch Tensor: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtensor\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Convert the PyTorch tensor to a NumPy array\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m numpy_array \u001b[38;5;241m=\u001b[39m \u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumPy Array: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnumpy_array\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Convert a NumPy array to a PyTorch tensor\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Numpy is not available"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create a PyTorch tensor\n",
    "tensor = torch.ones(5)\n",
    "print(f\"PyTorch Tensor: {tensor}\")\n",
    "\n",
    "# Convert the PyTorch tensor to a NumPy array\n",
    "numpy_array = tensor.numpy()\n",
    "print(f\"NumPy Array: {numpy_array}\")\n",
    "\n",
    "# Convert a NumPy array to a PyTorch tensor\n",
    "numpy_array = np.array([1, 2, 3])\n",
    "tensor = torch.from_numpy(numpy_array)\n",
    "print(f\"Tensor from NumPy Array: {tensor}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6xD2puc5qQZN"
   },
   "source": [
    "# [Optional] Moving PyTorch Tensors onto the GPU ⚡️\n",
    "(Applicable only if your system has a CUDA enabled GPU)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MQnXaNp0qwDP"
   },
   "outputs": [],
   "source": [
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "  device = torch.device(\"cuda\")          # a CUDA device object\n",
    "  x = torch.ones(5, device=device)       # directly create a tensor on GPU\n",
    "  y = torch.ones(5)\n",
    "  y = y.to(device)                       # or just use strings ``.to(\"cuda\")``\n",
    "  z = x + y\n",
    "  print(z)\n",
    "  print(z.to(\"cpu\", torch.double))       # ``.to`` can also change dtype together!\n",
    "else:\n",
    "  print(\"CUDA is not available.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PN1LptnZryTp"
   },
   "source": [
    "## Autograd\n",
    "\n",
    "- PyTorch's Autodiff tool.\n",
    "- Tracks the operations performed on a tensors in a forward pass.\n",
    "- When `backward()` is called gradients are auto-computed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "B3c_CtFFNu2S"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchviz in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (0.0.2)\n",
      "Requirement already satisfied: torch in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torchviz) (2.2.2)\n",
      "Requirement already satisfied: graphviz in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torchviz) (0.20.3)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch->torchviz) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch->torchviz) (4.12.2)\n",
      "Requirement already satisfied: sympy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch->torchviz) (1.13.3)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch->torchviz) (3.4.1)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch->torchviz) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch->torchviz) (2024.9.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jinja2->torch->torchviz) (3.0.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from sympy->torch->torchviz) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "oOdNQB1yq4dg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0014, 0.0051, 0.7028],\n",
      "        [0.3016, 0.6373, 0.3368]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wz/5btxyf0s4ydgg3zjpmyrn9g40000gn/T/ipykernel_2880/1075081989.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(torch.rand(2,3), requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor with autograd enabled\n",
    "x = torch.tensor(torch.rand(2,3), requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "us5HAOcssUFv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0028, 0.0102, 1.4056],\n",
      "        [0.6032, 1.2746, 0.6735]], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Perform some operation on the tensor and print it\n",
    "y = x * 2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0s88yt0qsYLc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6617, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Perform some more combinations of operations\n",
    "z = y.mean()\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "b-LMVruPPUqq"
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 12.1.2 (20240928.0832)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"108pt\" height=\"281pt\"\n",
       " viewBox=\"0.00 0.00 108.00 280.50\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 276.5)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-276.5 104,-276.5 104,4 -4,4\"/>\n",
       "<!-- 4552533840 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>4552533840</title>\n",
       "<polygon fill=\"#caff70\" stroke=\"black\" points=\"77,-32.75 23,-32.75 23,0 77,0 77,-32.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"50\" y=\"-7.25\" font-family=\"monospace\" font-size=\"10.00\"> ()</text>\n",
       "</g>\n",
       "<!-- 4569297008 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>4569297008</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"97,-89.5 3,-89.5 3,-68.75 97,-68.75 97,-89.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"50\" y=\"-76\" font-family=\"monospace\" font-size=\"10.00\">MeanBackward0</text>\n",
       "</g>\n",
       "<!-- 4569297008&#45;&gt;4552533840 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>4569297008&#45;&gt;4552533840</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M50,-68.36C50,-61.89 50,-53.05 50,-44.55\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"53.5,-44.55 50,-34.55 46.5,-44.55 53.5,-44.55\"/>\n",
       "</g>\n",
       "<!-- 4569296576 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>4569296576</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"94,-146.25 6,-146.25 6,-125.5 94,-125.5 94,-146.25\"/>\n",
       "<text text-anchor=\"middle\" x=\"50\" y=\"-132.75\" font-family=\"monospace\" font-size=\"10.00\">MulBackward0</text>\n",
       "</g>\n",
       "<!-- 4569296576&#45;&gt;4569297008 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>4569296576&#45;&gt;4569297008</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M50,-125.09C50,-118.47 50,-109.47 50,-101.27\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"53.5,-101.34 50,-91.34 46.5,-101.34 53.5,-101.34\"/>\n",
       "</g>\n",
       "<!-- 4569296336 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>4569296336</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"100,-203 0,-203 0,-182.25 100,-182.25 100,-203\"/>\n",
       "<text text-anchor=\"middle\" x=\"50\" y=\"-189.5\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 4569296336&#45;&gt;4569296576 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>4569296336&#45;&gt;4569296576</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M50,-181.84C50,-175.22 50,-166.22 50,-158.02\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"53.5,-158.09 50,-148.09 46.5,-158.09 53.5,-158.09\"/>\n",
       "</g>\n",
       "<!-- 4557642000 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4557642000</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"79,-272.5 21,-272.5 21,-239 79,-239 79,-272.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"50\" y=\"-259\" font-family=\"monospace\" font-size=\"10.00\">x</text>\n",
       "<text text-anchor=\"middle\" x=\"50\" y=\"-246.25\" font-family=\"monospace\" font-size=\"10.00\"> (2, 3)</text>\n",
       "</g>\n",
       "<!-- 4557642000&#45;&gt;4569296336 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>4557642000&#45;&gt;4569296336</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M50,-238.69C50,-231.35 50,-222.57 50,-214.71\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"53.5,-214.98 50,-204.98 46.5,-214.98 53.5,-214.98\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x10fff8810>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now lets see what the computation graph looks like\n",
    "import torchviz\n",
    "torchviz.make_dot(z, params={'x': x})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "lDS4f4Q2stvm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3333, 0.3333, 0.3333],\n",
      "        [0.3333, 0.3333, 0.3333]])\n",
      "False\n",
      "False\n",
      "True\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# Perform backpropagation\n",
    "z.backward()\n",
    "\n",
    "# Print the gradients of x\n",
    "print(x.grad)\n",
    "\n",
    "# Disable gradient tracking\n",
    "with torch.no_grad():\n",
    "  x = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)\n",
    "  y = x * 2\n",
    "  print(y.requires_grad)\n",
    "\n",
    "\n",
    "# Another way to disable gradient tracking\n",
    "x = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)\n",
    "y = x.detach() * 2\n",
    "print(y.requires_grad)\n",
    "\n",
    "x = torch.randn(3, requires_grad=True)\n",
    "print(x.requires_grad)\n",
    "y = x.detach()\n",
    "print(y.requires_grad)\n",
    "x.requires_grad_(False)\n",
    "print(x.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
